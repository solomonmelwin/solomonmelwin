{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0bal4Xr8c4xbcNMWC7sGg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/solomonmelwin/solomonmelwin/blob/main/weather_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GO_vUQYGKYpc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdvsb-7sKoPM",
        "outputId": "8e685cb6-ce2c-4cb3-d925-8fc428740dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download nikhil7280/weather-type-classification\n",
        "!unzip weather-type-classification.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lFYpC4lLvrS",
        "outputId": "62380373-6ed3-4245-fa7f-57317de77ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/nikhil7280/weather-type-classification\n",
            "License(s): other\n",
            "weather-type-classification.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  weather-type-classification.zip\n",
            "replace weather_classification_data.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "print(df.head())df = pd.read_csv('weather_classification_data.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHhGnJNdMglg",
        "outputId": "45182a99-0025-40ea-9d33-0f39a6aa8e27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Temperature  Humidity  Wind Speed  Precipitation (%)    Cloud Cover  \\\n",
            "0         14.0        73         9.5               82.0  partly cloudy   \n",
            "1         39.0        96         8.5               71.0  partly cloudy   \n",
            "2         30.0        64         7.0               16.0          clear   \n",
            "3         38.0        83         1.5               82.0          clear   \n",
            "4         27.0        74        17.0               66.0       overcast   \n",
            "\n",
            "   Atmospheric Pressure  UV Index  Season  Visibility (km)  Location  \\\n",
            "0               1010.82         2  Winter              3.5    inland   \n",
            "1               1011.43         7  Spring             10.0    inland   \n",
            "2               1018.72         5  Spring              5.5  mountain   \n",
            "3               1026.25         7  Spring              1.0   coastal   \n",
            "4                990.67         1  Winter              2.5  mountain   \n",
            "\n",
            "  Weather Type  \n",
            "0        Rainy  \n",
            "1       Cloudy  \n",
            "2        Sunny  \n",
            "3        Sunny  \n",
            "4        Rainy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rsZEvtUNapW",
        "outputId": "ec04a106-9373-4cae-d428-18ec6d4e6329"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13200 entries, 0 to 13199\n",
            "Data columns (total 11 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   Temperature           13200 non-null  float64\n",
            " 1   Humidity              13200 non-null  int64  \n",
            " 2   Wind Speed            13200 non-null  float64\n",
            " 3   Precipitation (%)     13200 non-null  float64\n",
            " 4   Cloud Cover           13200 non-null  object \n",
            " 5   Atmospheric Pressure  13200 non-null  float64\n",
            " 6   UV Index              13200 non-null  int64  \n",
            " 7   Season                13200 non-null  object \n",
            " 8   Visibility (km)       13200 non-null  float64\n",
            " 9   Location              13200 non-null  object \n",
            " 10  Weather Type          13200 non-null  object \n",
            "dtypes: float64(5), int64(2), object(4)\n",
            "memory usage: 1.1+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Assuming there is a column named 'weather_type' as the target label\n",
        "label_col = 'Weather Type'  # Update this based on the actual column name in the dataset\n",
        "X = df.drop(columns=[label_col])  # Features\n",
        "y = df[label_col]  # Target label\n",
        "\n",
        "# Encode the target labels\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Separate numerical and categorical features\n",
        "numerical_features = X_train.select_dtypes(include=['number']).columns\n",
        "categorical_features = X_train.select_dtypes(exclude=['number']).columns\n",
        "\n",
        "# Create transformers for numerical and categorical features\n",
        "numeric_transformer = StandardScaler()\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
        "\n",
        "# Combine transformers using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Fit and transform the data\n",
        "X_train = preprocessor.fit_transform(X_train)\n",
        "X_test = preprocessor.transform(X_test)"
      ],
      "metadata": {
        "id": "iUyd-c4QQl2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Initialize models\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "decision_tree = DecisionTreeClassifier()\n",
        "random_forest = RandomForestClassifier(n_estimators=100)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Create a dictionary of models to compare\n",
        "models = {\n",
        "    \"Logistic Regression\": log_reg,\n",
        "    \"Decision Tree\": decision_tree,\n",
        "    \"Random Forest\": random_forest,\n",
        "    \"KNN\": knn\n",
        "}\n"
      ],
      "metadata": {
        "id": "Hsyve6JORB__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_models(models, X_train, y_train, X_test, y_test):\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nTraining {name}...\")\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Classification Report for {name}:\\n{classification_report(y_test, y_pred)}\")\n",
        "        print(f\"Confusion Matrix for {name}:\\n{confusion_matrix(y_test, y_pred)}\")\n",
        "        results[name] = accuracy\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "IvigIz0yRGc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = evaluate_models(models, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvhJ3RpVRgoS",
        "outputId": "66dc895f-cc4d-4aef-c361-e59835e203be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression...\n",
            "Logistic Regression Accuracy: 0.8708\n",
            "Classification Report for Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83       651\n",
            "           1       0.86      0.84      0.85       647\n",
            "           2       0.89      0.94      0.91       701\n",
            "           3       0.92      0.86      0.89       641\n",
            "\n",
            "    accuracy                           0.87      2640\n",
            "   macro avg       0.87      0.87      0.87      2640\n",
            "weighted avg       0.87      0.87      0.87      2640\n",
            "\n",
            "Confusion Matrix for Logistic Regression:\n",
            "[[549  57  20  25]\n",
            " [ 46 543  50   8]\n",
            " [ 21   8 658  14]\n",
            " [ 52  25  15 549]]\n",
            "\n",
            "Training Decision Tree...\n",
            "Decision Tree Accuracy: 0.9098\n",
            "Classification Report for Decision Tree:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89       651\n",
            "           1       0.90      0.90      0.90       647\n",
            "           2       0.93      0.94      0.94       701\n",
            "           3       0.92      0.91      0.91       641\n",
            "\n",
            "    accuracy                           0.91      2640\n",
            "   macro avg       0.91      0.91      0.91      2640\n",
            "weighted avg       0.91      0.91      0.91      2640\n",
            "\n",
            "Confusion Matrix for Decision Tree:\n",
            "[[579  38  15  19]\n",
            " [ 36 580  14  17]\n",
            " [ 16  10 662  13]\n",
            " [ 23  15  22 581]]\n",
            "\n",
            "Training Random Forest...\n",
            "Random Forest Accuracy: 0.9140\n",
            "Classification Report for Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.90      0.89       651\n",
            "           1       0.91      0.91      0.91       647\n",
            "           2       0.93      0.94      0.94       701\n",
            "           3       0.93      0.90      0.92       641\n",
            "\n",
            "    accuracy                           0.91      2640\n",
            "   macro avg       0.91      0.91      0.91      2640\n",
            "weighted avg       0.91      0.91      0.91      2640\n",
            "\n",
            "Confusion Matrix for Random Forest:\n",
            "[[588  34  17  12]\n",
            " [ 34 589  11  13]\n",
            " [ 18   7 660  16]\n",
            " [ 29  15  21 576]]\n",
            "\n",
            "Training KNN...\n",
            "KNN Accuracy: 0.8966\n",
            "Classification Report for KNN:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.88      0.87       651\n",
            "           1       0.87      0.89      0.88       647\n",
            "           2       0.94      0.94      0.94       701\n",
            "           3       0.92      0.87      0.90       641\n",
            "\n",
            "    accuracy                           0.90      2640\n",
            "   macro avg       0.90      0.90      0.90      2640\n",
            "weighted avg       0.90      0.90      0.90      2640\n",
            "\n",
            "Confusion Matrix for KNN:\n",
            "[[573  45  12  21]\n",
            " [ 37 579  18  13]\n",
            " [ 14  17 658  12]\n",
            " [ 42  27  15 557]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models, layers\n",
        "\n",
        "# Define a simple neural network\n",
        "nn_model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(len(le.classes_), activation='softmax')  # Output layer for multi-class classification\n",
        "])\n",
        "\n",
        "# Compile the neural network\n",
        "nn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the neural network\n",
        "history = nn_model.fit(X_train, y_train, epochs=20, validation_split=0.2, batch_size=32)\n",
        "\n",
        "# Evaluate the neural network\n",
        "nn_loss, nn_accuracy = nn_model.evaluate(X_test, y_test)\n",
        "print(f\"\\nNeural Network Accuracy: {nn_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7q63qSUTOW7",
        "outputId": "16e68d42-ae8a-4598-eb76-5b438d6fbc95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6516 - loss: 0.9131 - val_accuracy: 0.8939 - val_loss: 0.3269\n",
            "Epoch 2/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8911 - loss: 0.3215 - val_accuracy: 0.9115 - val_loss: 0.2622\n",
            "Epoch 3/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9045 - loss: 0.2587 - val_accuracy: 0.9081 - val_loss: 0.2476\n",
            "Epoch 4/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2381 - val_accuracy: 0.9115 - val_loss: 0.2329\n",
            "Epoch 5/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2317 - val_accuracy: 0.9157 - val_loss: 0.2211\n",
            "Epoch 6/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2182 - val_accuracy: 0.9115 - val_loss: 0.2176\n",
            "Epoch 7/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2055 - val_accuracy: 0.9138 - val_loss: 0.2157\n",
            "Epoch 8/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2027 - val_accuracy: 0.9176 - val_loss: 0.2072\n",
            "Epoch 9/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9207 - loss: 0.1871 - val_accuracy: 0.9176 - val_loss: 0.2070\n",
            "Epoch 10/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9231 - loss: 0.1871 - val_accuracy: 0.9167 - val_loss: 0.2071\n",
            "Epoch 11/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.1952 - val_accuracy: 0.9129 - val_loss: 0.2092\n",
            "Epoch 12/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.1855 - val_accuracy: 0.9157 - val_loss: 0.2043\n",
            "Epoch 13/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.1752 - val_accuracy: 0.9171 - val_loss: 0.2035\n",
            "Epoch 14/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9283 - loss: 0.1727 - val_accuracy: 0.9115 - val_loss: 0.2105\n",
            "Epoch 15/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9289 - loss: 0.1667 - val_accuracy: 0.9143 - val_loss: 0.2026\n",
            "Epoch 16/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9385 - loss: 0.1549 - val_accuracy: 0.9143 - val_loss: 0.2043\n",
            "Epoch 17/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9285 - loss: 0.1669 - val_accuracy: 0.9176 - val_loss: 0.2046\n",
            "Epoch 18/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.1613 - val_accuracy: 0.9072 - val_loss: 0.2109\n",
            "Epoch 19/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9327 - loss: 0.1603 - val_accuracy: 0.9171 - val_loss: 0.2049\n",
            "Epoch 20/20\n",
            "\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9328 - loss: 0.1559 - val_accuracy: 0.9148 - val_loss: 0.2060\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9105 - loss: 0.2256\n",
            "\n",
            "Neural Network Accuracy: 0.9072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions for the neural network\n",
        "y_pred_nn = nn_model.predict(X_test).argmax(axis=1)\n",
        "print(f\"Classification Report for Neural Network:\\n{classification_report(y_test, y_pred_nn)}\")\n",
        "print(f\"Confusion Matrix for Neural Network:\\n{confusion_matrix(y_test, y_pred_nn)}\")\n",
        "\n",
        "\n",
        "\n",
        "# Combine the accuracy of all models including neural network\n",
        "results[\"Neural Network\"] = nn_accuracy\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3bQ85dtUkMu",
        "outputId": "6b419b83-18c0-408f-89e4-94bc79770d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Classification Report for Neural Network:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.87      0.89       651\n",
            "           1       0.88      0.91      0.89       647\n",
            "           2       0.93      0.94      0.94       701\n",
            "           3       0.91      0.90      0.90       641\n",
            "\n",
            "    accuracy                           0.91      2640\n",
            "   macro avg       0.91      0.91      0.91      2640\n",
            "weighted avg       0.91      0.91      0.91      2640\n",
            "\n",
            "Confusion Matrix for Neural Network:\n",
            "[[567  38  18  28]\n",
            " [ 28 589  15  15]\n",
            " [  7  16 662  16]\n",
            " [ 21  27  16 577]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nModel Accuracies:\")\n",
        "for model_name, acc in results.items():\n",
        "    print(f\"{model_name}: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvFw9h_eUQPv",
        "outputId": "64e1ce28-3b77-40ed-9bba-99bf859a828e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracies:\n",
            "Logistic Regression: 0.8708\n",
            "Decision Tree: 0.9098\n",
            "Random Forest: 0.9140\n",
            "KNN: 0.8966\n",
            "Neural Network: 0.9072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = max(results, key=results.get)\n",
        "print(f\"\\nThe best performing model is: {best_model} with accuracy of {results[best_model]:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8LaR4MBU871",
        "outputId": "3f2c2125-1a73-4957-e81d-cc26a7cb1b59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The best performing model is: Random Forest with accuracy of 0.9140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Choose the 3 features you want to use for retraining\n",
        "selected_features = ['Temperature', 'Humidity', 'Wind Speed']  # Replace with the actual feature names\n",
        "\n",
        "# Subset the dataset for these 3 features\n",
        "X = df[selected_features]\n",
        "y = df[\"Weather Type\"]  # Target label (e.g., 'weather_type')\n",
        "\n",
        "# Continue with preprocessing and training the model\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Random Forest with the selected features\n",
        "random_forest = RandomForestClassifier(n_estimators=100)\n",
        "random_forest.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "yHj4Bk4Nbll4",
        "outputId": "2cf68aa4-2916-454d-fc4d-9afb6f57c24c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to take user input for 3 features and predict weather type\n",
        "def predict_weather(model, scaler, le):\n",
        "    print(\"Enter the values for the following 3 features:\")\n",
        "\n",
        "    # 3 features used in prediction (replace with actual feature names from your dataset)\n",
        "    temperature = float(input(\"Temperature (in Celsius): \"))\n",
        "    humidity = float(input(\"Humidity (percentage): \"))\n",
        "    wind_speed = float(input(\"Wind Speed (km/h): \"))\n",
        "\n",
        "    # Create an array of input values for only the selected 3 features\n",
        "    user_input = np.array([[temperature, humidity, wind_speed]])\n",
        "\n",
        "    # Scale the input using the scaler fitted on the training data\n",
        "    user_input_scaled = scaler.transform(user_input)\n",
        "\n",
        "    # Predict the weather type using the trained Random Forest model\n",
        "    prediction = model.predict(user_input_scaled)\n",
        "\n",
        "    # Decode the predicted label to get the weather type\n",
        "    predicted_weather_type = le.inverse_transform(prediction)\n",
        "\n",
        "    print(f\"The predicted weather type is: {predicted_weather_type[0]}\")\n",
        "\n",
        "# Call this function to predict based on user input\n",
        "predict_weather(random_forest, scaler, le)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AXOfCgVfJ1J",
        "outputId": "a5045d72-0f2c-4ac1-ccec-ce71a9b6b6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the values for the following 3 features:\n",
            "Temperature (in Celsius): 30\n",
            "Humidity (percentage): 76\n",
            "Wind Speed (km/h): 13\n",
            "The predicted weather type is: Cloudy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}